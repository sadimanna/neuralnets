{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet v2 on EMNIST Digits.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "eTsH_ACC-Eum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "import numpy as np\n",
        "import time, random\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AK0lICAQplMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6If9W0t2DIkf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DATASET UPLOADS\n",
        "upload = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHb1smZVEC1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#NECESSARY TO ACCESS UPLOADED FILES, IDK WHY\n",
        "for k,v in uploaded.keys():\n",
        "  open(k,'wb').write(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ikep1j0MGF07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_images = np.load('emnist_digits_training_images.npy')\n",
        "training_labels = np.load('emnist_digits_training_labels.npy')\n",
        "test_images = np.load('emnist_digits_test_images.npy')\n",
        "test_labels = np.load('emnist_digits_test_labels.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oc7UBefEqqEC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss(logits,labels):\n",
        "\tlabels = tf.reshape(tf.cast(labels,tf.int64),[-1])\n",
        "\tcross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits,name='cross_entropy_per_example')\n",
        "  cross_entropy_mean = tf.reduce_mean(cross_entropy,name='mean_ce')\n",
        "  total_loss = tf.add(tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)),cross_entropy_mean,name='total_loss')\n",
        "\t\n",
        "  return total_loss\n",
        "\n",
        "def accuracy(logits,true_labels):\n",
        "\tpred_labels = tf.argmax(logits,1)\n",
        "\ttrue_labels = tf.cast(true_labels,tf.int64)\n",
        "\t#print pred_labels.get_shape().as_list(),true_labels\n",
        "\tcorrect_pred = tf.cast(tf.equal(pred_labels, true_labels), tf.float32)\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\treturn accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Abz08cIHquWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32,shape=[None,28,28],name='x')\n",
        "y = tf.placeholder(tf.int64,shape=[None],name='y')\n",
        "keep_prob = tf.placeholder(tf.float32,shape=(),name='keep_prob')\n",
        "#lr = tf.placeholder(tf.float32,shape=())\n",
        "mode = tf.placeholder(tf.bool,shape=(),name='mode')\n",
        "\n",
        "aug_img = tf.placeholder(tf.float32,shape=[28,28],name='aug_img')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXVZch4aq_Ln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rotate = tf.contrib.image.rotate(aug_img,-0.5+np.random.random(),interpolation='BILINEAR')\n",
        "img_affine = tf.contrib.image.transform(aug_img,[np.random.random() for i in xrange(8)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-4cTL3zgP-7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RESNET MODULE\n",
        "def resmod(name,xinput,numfilts,s,projection):\n",
        "  with tf.variable_scope(name):\n",
        "    #1x1\n",
        "    bn1 = tf.layers.batch_normalization(xinput,axis=3,training=mode,name=name+'bn1')\n",
        "    act1 = tf.nn.relu(bn1,name=name+'relu1')\n",
        "    conv1 = tf.layers.conv2d(act1,filters=numfilts,kernel_size=1,strides=1,padding='same',activation=None,kernel_initializer=tf.contrib.layeres.xavier_initializer(uniform=False),kernel_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005),dtype=tf.float32),name=name+'conv1_1x1')\n",
        "    #3x3\n",
        "    bn2 = tf.layers.batch_normalization(conv1,axis=3,training=mode,name=name+'bn2')\n",
        "    act2 = tf.nn.relu(bn2,name=name+'relu2')\n",
        "    conv2 = tf.layers.conv2d(act2,filters=numfilts,kernel_size=3,strides=s,padding='same',activation=None,kernel_initializer=tf.contrib.layeres.xavier_initializer(uniform=False),kernel_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005),dtype=tf.float32),name=name+'conv2_3x3')\n",
        "    #1x1\n",
        "    bn3 = tf.layers.batch_normalization(conv2,axis=3,training=mode,name=name+'bn3')\n",
        "    act3 = tf.nn.relu(bn3,name=nae+'relu3')\n",
        "    conv3 = tf.layers.conv2d(act3,filters=4*numfilts,kernel_size=1,strides=1,padding='same',activation=None,kernel_initializer=tf.contrib.layeres.xavier_initializer(uniform=False),kernel_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005),dtype=tf.float32),name=name+'conv3_1x1')\n",
        "    \n",
        "    #SHORTCUT\n",
        "    if projection or s==2:\n",
        "      shortcut = tf.layers.conv2d(xinput,filters=4*numfilts,kernel_size=1,strides=s,padding='same',activation=None,kernel_initializer=tf.contrib.layeres.xavier_initializer(uniform=False),kernel_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005),dtype=tf.float32),name=name+'shortcut')\n",
        "    else:\n",
        "      shortcut = xinput\n",
        "      \n",
        "    res_block_out = tf.add(conv3,shortcut,name=name+'output')\n",
        "  \n",
        "  return res_block_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjACEUQwPZna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RESNET V2\n",
        "with tf.device('/gpu:0'):\n",
        "  #28X28X3\n",
        "  conv1 = tf.layers.conv2d(tf.reshape(x,shape=[-1,28,28,1]),filters=64,kernel_size=3,strides=1,padding='same',activation=tf.nn.relu,kernel_initializer=tf.contrib.layeres.xavier_initializer(uniform=False),kernel_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0005),dtype=tf.float32),name='conv1')\n",
        "  pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=1,padding='same',name='pool1')\n",
        "  #28x28x64\n",
        "  res1_1 = resmod('res1_1',pool1,64,1,True)\n",
        "  res1_2 = resmod('res1_2',res1_1,64,1,False)\n",
        "  res1_3_= resmod('res1_3',res1_2,64,1,False)\n",
        "  #28X28X256\n",
        "  res2_1 = resmod('res2_1',res1_3,128,2,True)\n",
        "  #14X14X512\n",
        "  res2_2 = resmod('res2_2',res2_1,128,1,False)\n",
        "  res2_3 = resmod('res2_3',res2_2,128,1,False)\n",
        "  #res2_4 = resmod('res2_4',res2_3,128,1,False)\n",
        "  #14X14X512\n",
        "  res3_1 = resmod('res3_1',res2_3,256,2,True)\n",
        "  #7X7X1024\n",
        "  res3_2 = resmod('res3_2',res3_1,256,1,False)\n",
        "  res3_3 = resmod('res3_3',res3_2,256,1,False)\n",
        "  #res3_4 = resmod('res3_4',res3_3,256,1,False)\n",
        "  #res3_5 = resmod('res3_5',res3_4,256,1,False)\n",
        "  #res3_6 = resmod('res3_6',res3_5,256,1,False)\n",
        "  #7X7X1024\n",
        "  res4_1 = resmod('res4_1',res3_3,512,2,True)\n",
        "  #3X3X2048\n",
        "  res4_2 = resmod('res4_2',res4_1,512,1,False)\n",
        "  res4_3 = resmod('res4_3',res4_2,512,1,False)\n",
        "  #3X3X2048\n",
        "  relu1 = t.nn.relu(res4_3,name='relu1')\n",
        "  avg_pool = tf.layers.average_pooling2d(relu1,pool_size=3,strides=1,padding='valid',name='avg_pool')\n",
        "  drouput1 = tf.layers.dropout(avg_pool,rate=keep_prob,training=mode)\n",
        "  logits = tf.layers.dense(dropout1,units=10)\n",
        "  \n",
        "  cost = loss(logits,y)\n",
        "  \n",
        "  train_op = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "  \n",
        "  update_ops = tf.get_collections(tf.GraphKeys.UPDATE_OPS)\n",
        "  \n",
        "  with tf.control_dependencies(update_ops):\n",
        "    opt_op = train_op.minimize(cost)\n",
        "  \n",
        "  acc = accuracy(logits,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ty1POQkPnJsE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cTc53fvnfSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "ne = 0\n",
        "tracc=[]\n",
        "valacc=[]\n",
        "trerr=[]\n",
        "valerr=[]\n",
        "batch_size = 100\n",
        "numiter = 2000\n",
        "index=np.arange(200000)\n",
        "index_t = np.arange(40000)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  while(ne<epochs):\n",
        "    print 'Epoch:: ',ne+1,'-->'\n",
        "    stime = time.time()\n",
        "    if ne != 0:\n",
        "\t\t  np.random.shuffle(index)\n",
        "\t\t  images = images[index]\n",
        "\t\t  labels = labels[index]\n",
        "    for niter in xrange(numiter):\n",
        "      #if (niter+1)%100==0:\n",
        "        #print 'Iter::',niter+1,'---------'\n",
        "      offset = niter*batch_size\n",
        "      x_iter, y_iter = np.array(images[offset:offset+batch_size,:,:]), np.array(labels[offset:offset+batch_size])\n",
        "      \n",
        "      #Training Dict\n",
        "      feed_trdict={x:x_iter,y:y_iter,keep_prob:0.8,mode:True}\n",
        "\t\t  \n",
        "      #Train\n",
        "      sess.run(opt_op,feed_dict=feed_trdict)\n",
        "    \n",
        "    \n",
        "    #Calculate accuracy of Training set\n",
        "    print 'Calculating Loss and Accuracy...'\n",
        "    tr_loss = sess.run(cost,feed_dict=feed_trdict)\n",
        "    tr_acc = sess.run(acc,feed_dict = feed_trdict)\n",
        "    \n",
        "    #Calculate accuracy of Validation set\n",
        "    np.random.shuffle(index_t)\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    for j in xrange(400):\n",
        "      val_loss += sess.run(cost,feed_dict = {x:test_imgs[index_t[j*100:(j+1)*100]],y:test_labels[index_t[j*100:(j+1)*100]],keep_prob:1.0,mode:False})\n",
        "      val_acc += sess.run(acc,feed_dict = {x:test_imgs[index_t[j*100:(j+1)*100]],y:test_labels[index_t[j*100:(j+1)*100]],keep_prob:1.0,mode:False})\n",
        "    val_loss/=400\n",
        "    val_acc/=400\n",
        "    print 'Appending values'\n",
        "    valacc.append(val_acc)\n",
        "    tracc.append(tr_acc)\n",
        "    trerr.append(tr_loss)\n",
        "    valerr.append(val_loss)\n",
        "    print 'Epoch..',ne+1,'...'\n",
        "    print 'Training cost::',tr_loss,' Validation Cost:: ',val_loss\n",
        "    print 'Training accuracy::',tr_acc*100,'%',' Validation accuracy::',val_acc*100,'%'\n",
        "    print 'Time reqd.::',(time.time()-stime)/60,'mins...'\n",
        "    ne = ne + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRBbR_Ledpvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(tracc)\n",
        "plt.plot(valacc)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_EYAb7pekES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(trerr)\n",
        "plt.plot(valerr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbN0micRen_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#INFERENCE\n",
        "test_acc=[]\n",
        "tindex = np.arange(40000)\n",
        "\n",
        "for nepoch in xrange(100):\n",
        "  stime = time.time()\n",
        "\tif nepoch !=0:\n",
        "\t\tnp.random.shuffle(tindex)\n",
        "\t\ttest_x = test_x[index]\n",
        "\t\ttest_y = test_y[index]\n",
        "\ttest_loss = sess.run(cost,feed_dict = {feed_images:test_x,feed_labels:test_y,keep_prob:1.0,mode=False})\n",
        "\ttest_acc = sess.run(acc,feed_dict = {feed_images:test_x,feed_labels:test_y,keep_prob:1.0,mode=False})\n",
        "\tprint 'Epoch..',ne+1,'...'\n",
        "\tprint 'Time reqd.::',(time.time()-stime)/60,'mins...'\n",
        "  test_acc.append(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MUM99b-DyW35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGuCeZZQ5iuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVE MODEL\n",
        "graph = tf.get_default_graph()\n",
        "\n",
        "with graph.as_default():\n",
        "  input_dict = {\"x\":x,\"y\":y,\"keep_prob\":keep_prob,\"aug_img\":aug_img,\"mode\":mode}\n",
        "  output_dict = {\"logits\":logits,\"aux_logits\":aux_logits}\n",
        "  tf.saved_model.simple_save(sess,'/mnist_saved_model/',input_dict,output_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "syEL4eNuyjs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}